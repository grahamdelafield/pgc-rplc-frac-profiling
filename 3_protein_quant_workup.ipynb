{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import altair as alt\n",
    "import copy\n",
    "import re \n",
    "import ntpath \n",
    "from commons import data_processing\n",
    "from commons.DataProcessors import msfragger\n",
    "from commons.APICallers import uniprot\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_colors = alt.Color('column:N',\n",
    "    scale=alt.Scale(\n",
    "        domain=[\"PGC\", \"RPLC\", \"both\"],\n",
    "        range=[\"#D56E3B\", \"#58728C\", \"#AAAAAA\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "axis_params = alt.Axis(\n",
    "    labelFontSize=14,\n",
    "    labelFontWeight=600,\n",
    "    labelAngle=0,\n",
    "    labelFlush=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data from pax db\n",
    "# https://pax-db.org/dataset/9606/1502934799/\n",
    "pax = pd.read_csv('./data/paxdb/9606-WHOLE_ORGANISM-integrated.txt', delimiter='\\t', skiprows=range(10))\n",
    "pax.columns = [c.replace('#', '') for c in pax.columns]\n",
    "\n",
    "# read in uniprot mappings from paxdb\n",
    "# https://pax-db.org/download\n",
    "pax_map = pd.read_csv('./data/paxdb/paxdb-uniprot-links-v4.2.tsv', delimiter='\\t', header=None)\n",
    "pax_map.columns = ['internal_id', 'uniprot_id']\n",
    "\n",
    "# filter mappings to only human proteins\n",
    "pax_map_human = pax_map[pax_map.uniprot_id.str.contains('HUMAN')]\n",
    "pax_human_lookup = dict(zip(pax_map_human.internal_id.tolist(), pax_map_human.uniprot_id.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map uniprot entries to pax db\n",
    "pax.loc[:, \"uniprot_id\"] = pax.string_external_id.map(pax_human_lookup)\n",
    "pax.loc[:, \"rank\"] = [i for i in range(1, len(pax)+1)]\n",
    "pax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a test chart to see if the data is how we expect\n",
    "alt.Chart(pax).mark_circle().encode(\n",
    "    x=alt.X('rank:Q', title='paxdb rank',\n",
    "        axis=axis_params),\n",
    "    y=alt.Y('log_abundance:Q', title='paxdf abundance',\n",
    "        axis=axis_params),\n",
    "    # size='abundance:Q'\n",
    ").transform_calculate(\n",
    "    log_abundance='log(datum.abundance)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we read in experimental data\n",
    "files = data_processing.get_files(r'./data/fractions/', exts=['psm.tsv'])\n",
    "\n",
    "# use msfragger module to process data\n",
    "msf = None\n",
    "for file in files:\n",
    "    m = msfragger.msf_processor([file])\n",
    "\n",
    "    # extract fraction and column info\n",
    "    dirname = ntpath.dirname(file)\n",
    "    spl = re.split(r'[\\\\\\/]', dirname)\n",
    "    column, fraction = spl[-2:]\n",
    "    m.add_special_column('fraction', fraction)\n",
    "    m.add_special_column('column', column)\n",
    "\n",
    "    if msf is None:\n",
    "        msf = m\n",
    "    else:\n",
    "        msf.join_processors(m)\n",
    "\n",
    "# grab data\n",
    "df = msf.data\n",
    "msf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine based on which column identified the proteins\n",
    "exp_proteins = df.groupby(['column', 'entry_name', 'protein_id', 'gene'], as_index=False).count()\n",
    "\n",
    "# find all proteins identified in both\n",
    "counts = exp_proteins.protein_id.value_counts()\n",
    "pairs = counts[counts.values==2].keys()\n",
    "print(f'{len(counts)} total proteins, {len(pairs)} identified in both columns')\n",
    "\n",
    "# change column name to 'both'\n",
    "exp_proteins.loc[(exp_proteins.protein_id.isin(pairs)), 'column'] = 'both'\n",
    "\n",
    "# remove those duplicates\n",
    "exp_proteins = exp_proteins.drop_duplicates(['column', 'entry_name'])\n",
    "\n",
    "# keep only needed rows\n",
    "exp_proteins = exp_proteins.iloc[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to pax db based on entry name\n",
    "pax_join = pax.merge(exp_proteins, left_on='uniprot_id', right_on='entry_name')\n",
    "\n",
    "# calculate log10 abundance\n",
    "# since it includes values << 10, we will multiply by 1000 for normalization\n",
    "pax_join.loc[:, 'log10_abundance'] = np.log10(pax_join.abundance*1000)\n",
    "\n",
    "# normalize\n",
    "pax_join.loc[:, 'norm10_abundance'] = pax_join.log10_abundance /  np.max(pax_join.log10_abundance)\n",
    "\n",
    "abund_dots = alt.Chart(pax_join).mark_circle(\n",
    "    size=10\n",
    ").encode(\n",
    "    x=alt.X('rank:Q', title='paxdb rank',\n",
    "        axis=axis_params),\n",
    "    y=alt.Y('norm10_abundance:Q', title='paxdf abundance, normalized',\n",
    "        axis=axis_params),\n",
    "    # size='abundance:Q',\n",
    "    color=column_colors,\n",
    "    column='column:N'\n",
    ").properties(\n",
    "    width=100,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abund_box = alt.Chart(pax_join, width=53).mark_boxplot(\n",
    "    size=40\n",
    ").encode(\n",
    "    y=alt.Y('norm10_abundance:Q', title='paxdb abundance, normalized',\n",
    "        axis=axis_params),\n",
    "    column='column:N',\n",
    "    color=column_colors\n",
    ").transform_calculate(\n",
    "    log_abundance='log(datum.abundance)'\n",
    ").configure_facet(\n",
    "    spacing=0\n",
    ").configure_view(\n",
    "    stroke=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abund_dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abund_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_data = pd.read_csv('./data/Uniprot/Uniprot_GO_BP.tsv', delimiter='\\t')\n",
    "uni_data = uni_data.dropna()\n",
    "\n",
    "columns = [c.lower().replace(' ', '_') for c in uni_data.columns]\n",
    "columns = [re.sub('[\\(\\)]', '', c) for c in columns]\n",
    "uni_data.columns = columns \n",
    "uni_data.loc[:, 'spl_go'] = uni_data.gene_ontology_biological_process.str.split('; ')\n",
    "uni_data = uni_data.explode('spl_go')\n",
    "\n",
    "uni_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_pax = pax_join.copy()\n",
    "\n",
    "uni_join = pax_join.merge(uni_data, on='entry_name')\n",
    "\n",
    "uni_select = data_processing.get_valid_counts(uni_join, 'spl_go', 50, filter='greater_equal')\n",
    "uni_select.loc[:, 'clean_go'] = uni_select.spl_go.map(lambda x: re.sub(r' \\[\\w*\\:\\w*\\]', '', x))\n",
    "order = uni_select.clean_go.value_counts().keys().tolist()\n",
    "\n",
    "test = uni_select.groupby(['column', 'clean_go'], as_index=False).mean()\n",
    "\n",
    "base = alt.Chart(uni_select).encode(\n",
    "    x=alt.X('column:N'),\n",
    "    y=alt.Y('mean(norm10_abundance):Q'),\n",
    "    color=column_colors\n",
    ")\n",
    "\n",
    "# alt.layer(base.mark_circle(size=15), base.mark_errorbar(extent='stdev')).facet(\n",
    "#     column=alt.Column('clean_go:N', sort=order)\n",
    "# ).configure_facet(spacing=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgc_good = [\"mRNA splicing, via spliceosome\",\n",
    "\"translation\",\n",
    "\"proteolysis\",\n",
    "\"vesicle mediated transport\",\n",
    "\"cytoplasmic translation\", \n",
    "\"protein localization\",\n",
    "\"regulation of expression\",\n",
    "\"lipid metabolic process\"]\n",
    "\n",
    "rplc_good = [\"positive regulation of NF-kappaB transcription factor activity\",\n",
    "\"protein import into nucleus\",\n",
    "\"regulation of cell shape\",\n",
    "\"protein-containing complex assembly\",\n",
    "\"signal transduction\"]\n",
    "\n",
    "axis_params = alt.Axis(\n",
    "    labelFontSize=14,\n",
    "    labelFontWeight=600,\n",
    "    labelAngle=0,\n",
    "    labelFlush=False\n",
    ")\n",
    "mod_x = axis_params.copy()\n",
    "mod_x['labelAngle'] = -45\n",
    "\n",
    "base = alt.Chart(uni_select[(uni_select.clean_go.isin(pgc_good))|(uni_select.clean_go.isin(rplc_good))]).encode(\n",
    "    x=alt.X('column:N',\n",
    "        axis=mod_x),\n",
    "    y=alt.Y('mean(norm10_abundance):Q',\n",
    "        axis=axis_params,\n",
    "        scale=alt.Scale(\n",
    "            domain=[0,1]\n",
    "        )),\n",
    "    color=column_colors\n",
    ").properties(\n",
    "    width=100,\n",
    "    height=100\n",
    ")\n",
    "\n",
    "alt.layer(base.mark_circle(size=50), base.mark_errorbar(extent='stdev')).facet(\n",
    "    column=alt.Column('clean_go:N', sort=order)\n",
    ").configure_facet(spacing=50)\n",
    "\n",
    "base.mark_boxplot(size=25).facet(\n",
    "    column=alt.Column('clean_go:N', sort=order)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "997be7fa6ee3aea2187d81d19d8bcf997dfd02a0abc6e4a12a1cd736d7582d2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
